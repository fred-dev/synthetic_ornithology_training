{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "machine_shape": "hm",
      "mount_file_id": "196rBgilOw53n6y2yG2IlZs9OAf9sh6xm",
      "authorship_tag": "ABX9TyOJaKCprfMqyQ8PRlnpVk+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fred-dev/synthetic_ornithology_training/blob/main/Wave_GAN_NEW_with_buckets_stateful_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install tinytag"
      ],
      "metadata": {
        "id": "sNqJUbmNZn5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import cpuinfo\n",
        "import os\n",
        "\n",
        "# Get CPU information\n",
        "cpu_info = cpuinfo.get_cpu_info()\n",
        "cpu_brand = cpu_info[\"brand_raw\"]\n",
        "print(\"CPU Brand:\", cpu_brand)\n",
        "\n",
        "# Check if the CPU is from AMD\n",
        "is_amd_cpu = \"AMD\" in cpu_brand\n",
        "\n",
        "# Set OpenBLAS backend if AMD CPU is detected\n",
        "if is_amd_cpu:\n",
        "    os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
        "    print(\"Switched to OpenBLAS backend for AMD CPU.\")\n",
        "else:\n",
        "    print(\"Using default backend.\")\n"
      ],
      "metadata": {
        "id": "l0XYRAD1ULNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2fHyssYY8N6"
      },
      "outputs": [],
      "source": [
        "# 1. Import required libraries\n",
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "from tinytag import TinyTag\n",
        "import json\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import wandb\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, SubsetRandomSampler\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "from torch.nn.functional import multi_head_attention_forward\n",
        "from torch.nn import MultiheadAttention\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import MultiheadAttention\n",
        "import logging\n",
        "from torch import autograd\n",
        "import sys\n",
        "\n",
        "print(\"Python verion: \" + sys.version)\n",
        "\n",
        "print(\"Pytorch version: \" + torch.__version__)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # Don't change this.\n",
        "audio_folder = \"/content/drive/MyDrive/colab_storage/ronxgin_data_samples\"\n",
        "audio_folder_all = \"/content/drive/MyDrive/colab_storage/audioWeather/audiofilesProcessed\"\n",
        "json_folder = \"/content/drive/MyDrive/colab_storage/ronxgin_data_samples\"\n",
        "model_path = \"/content/drive/MyDrive/colab_storage/modelData\"\n",
        "output_path = \"/content/drive/MyDrive/colab_storage/outputData\"\n",
        "bucketData_path = \"/content/drive/MyDrive/colab_storage/bucketData\"\n",
        "json_database_path = \"/content/drive/MyDrive/colab_storage/JSON_Database/synthetic_ornithology_complete.json\"\n",
        "json_database_normalised_path = \"/content/drive/MyDrive/colab_storage/JSON_Database/synthetic_ornithology_complete_normalised.json\"\n",
        "project_settings_json_path = \"/content/drive/MyDrive/colab_storage/Project_settings/s_o_settings.json\"\n",
        "\n"
      ],
      "metadata": {
        "id": "j-bx2eTsawdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def setupParameters(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        systemParams = json.load(file)\n",
        "\n",
        "    master_sample_rate = systemParams[\"sample_rate\"]\n",
        "    log_level = systemParams[\"log_level\"]\n",
        "    sequence_element_length_ms = systemParams[\"sequence_element_length_ms\"]\n",
        "    bucket_min_duration_ms = systemParams[\"bucket_min_duration_ms\"]\n",
        "    bucket_max_duration_ms = systemParams[\"bucket_max_duration_ms\"]\n",
        "    bucket_max_size_variation_ms = systemParams[\"bucket_max_size_variation_ms\"]\n",
        "\n",
        "    mel_n_fft = systemParams[\"mel_settings\"][\"mel_n_fft\"]\n",
        "    mel_hop_length = systemParams[\"mel_settings\"][\"mel_hop_length\"]\n",
        "    mel_n_mels = systemParams[\"mel_settings\"][\"mel_n_mels\"]\n",
        "    mel_window_fn = systemParams[\"mel_settings\"][\"mel_window_fn\"]\n",
        "    mel_normalized = systemParams[\"mel_settings\"][\"mel_normalized\"]\n",
        "\n",
        "    num_attention_heads = systemParams[\"hyperparameters\"][\"num_attention_heads\"]\n",
        "    num_epochs = systemParams[\"hyperparameters\"][\"num_epochs\"]\n",
        "    input_dim =  systemParams[\"hyperparameters\"][\"input_dim\"]\n",
        "    hidden_dim = systemParams[\"hyperparameters\"][\"hidden_dim\"]\n",
        "    num_layers = systemParams[\"hyperparameters\"][\"num_layers\"]\n",
        "    conditioning_dim = systemParams[\"hyperparameters\"][\"conditioning_dim\"]\n",
        "    learning_rate = systemParams[\"hyperparameters\"][\"learning_rate\"]\n",
        "    steps_per_element = math.ceil((master_sample_rate * sequence_element_length_ms / 1000) / mel_hop_length)\n",
        "\n",
        "\n",
        "    # Returning all the parameters as a dictionary\n",
        "    return {\n",
        "        \"master_sample_rate\": master_sample_rate,\n",
        "        \"log_level\": log_level,\n",
        "        \"sequence_element_length_ms\": sequence_element_length_ms,\n",
        "        \"bucket_min_duration_ms\": bucket_min_duration_ms,\n",
        "        \"bucket_max_duration_ms\": bucket_max_duration_ms,\n",
        "        \"bucket_max_size_variation_ms\": bucket_max_size_variation_ms,\n",
        "        \"mel_n_fft\": mel_n_fft,\n",
        "        \"mel_hop_length\": mel_hop_length,\n",
        "        \"mel_n_mels\": mel_n_mels,\n",
        "        \"mel_window_fn\": mel_window_fn,\n",
        "        \"mel_normalized\": mel_normalized,\n",
        "        \"num_attention_heads\": num_attention_heads,\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"input_dim\": input_dim,\n",
        "        \"hidden_dim\": hidden_dim,\n",
        "        \"num_layers\": num_layers,\n",
        "        \"conditioning_dim\": conditioning_dim,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"steps_per_element\" : steps_per_element\n",
        "    }\n",
        "\n",
        "#Set up the logging configuration\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Global scope\n",
        "systemParams = setupParameters(project_settings_json_path)\n",
        "print(systemParams)  # print the parameters\n",
        "\n",
        "# Create a logger instance\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.DEBUG)  # Set logger level to DEBUG\n",
        "\n",
        "# Define custom log levels and their corresponding colors\n",
        "LOG_COLORS = {\n",
        "    logging.DEBUG: '\\033[94m',    # Blue\n",
        "    logging.INFO: '\\033[92m',     # Green\n",
        "    logging.WARNING: '\\033[93m',  # Yellow\n",
        "    logging.ERROR: '\\033[91m',    # Red\n",
        "    logging.CRITICAL: '\\033[91m'  # Red\n",
        "}\n",
        "\n",
        "# Create a custom log formatter to add colors\n",
        "class ColoredFormatter(logging.Formatter):\n",
        "    def format(self, record):\n",
        "        log_color = LOG_COLORS.get(record.levelno)\n",
        "        log_msg = super().format(record)\n",
        "        return f'{log_color}{record.levelname} - {log_msg}\\033[0m'\n",
        "\n",
        "\n",
        "for handler in logger.handlers:\n",
        "    logger.removeHandler(handler)\n",
        "\n",
        "# Create a console handler and set the log level\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.DEBUG)\n",
        "\n",
        "# Apply the custom log formatter to the console handler\n",
        "colored_formatter = ColoredFormatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "console_handler.setFormatter(colored_formatter)\n",
        "\n",
        "# Add the console handler to the logger\n",
        "logger.addHandler(console_handler)\n",
        "logger.propagate = False\n"
      ],
      "metadata": {
        "id": "k9Vq7ecg9-Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.debug(\"This is a debug message\")\n",
        "logger.info(\"This is an info message\")\n",
        "logger.warning(\"This is a warning message\")\n",
        "logger.error(\"This is an error message\")\n",
        "logger.critical(\"This is a critical message\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fAEOl2y1bkeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions for normalising parameters. These are fixed and named to make things simpler later time.\n",
        "def normalise_lat(lat):\n",
        "    return (lat - (-90)) / (90 - (-90))\n",
        "\n",
        "def normalise_lon(lon):\n",
        "    return (lon - (-180)) / (180 - (-180))\n",
        "\n",
        "def normalise_temp(temp, mean, std):\n",
        "    return (temp - mean) / std\n",
        "\n",
        "def normalise_humidity(humidity, mean, std):\n",
        "    return (humidity - mean) / std\n",
        "\n",
        "def normalise_wind_speed(wind_speed, mean, std):\n",
        "    return (wind_speed - mean) / std\n",
        "\n",
        "def normalise_wind_direction(wind_direction, mean, std):\n",
        "    return (wind_direction - mean) / std\n",
        "\n",
        "def normalise_pressure(pressure, mean, std):\n",
        "    return (pressure - mean) / std\n",
        "\n",
        "def normalise_elevation(elevation, mean, std):\n",
        "    return (elevation - mean) / std\n",
        "\n",
        "def normalise_minutes_of_day(minutes_of_day):\n",
        "    return minutes_of_day / 1440\n",
        "\n",
        "def normalise_day_of_year(day_of_year):\n",
        "    return (day_of_year - 1) / 364\n",
        "\n",
        "\n",
        "def preprocess_json(input_file_path, output_file_path, project_settings_file_path):\n",
        "    with open(input_file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Collect values for pre-normalization visualization\n",
        "    pre_normalized_data = {\n",
        "        \"Temperature\": [entry[\"main\"][\"temp\"] for entry in data],\n",
        "        \"Humidity\": [entry[\"main\"][\"humidity\"] for entry in data],\n",
        "        \"Wind Speed\": [entry[\"wind\"][\"speed\"] for entry in data],\n",
        "        \"Wind Direction\": [entry[\"wind\"][\"deg\"] for entry in data],\n",
        "        \"Pressure\": [entry[\"main\"][\"pressure\"] for entry in data],\n",
        "        \"Elevation\": [entry[\"elevation\"] for entry in data],\n",
        "        \"Minutes of Day\": [entry[\"minutesOfDay\"] for entry in data],\n",
        "        \"Day of Year\": [entry[\"dayOfYear\"] for entry in data]\n",
        "    }\n",
        "\n",
        "    # Plot pre-normalization graphs\n",
        "    fig, axs = plt.subplots(len(pre_normalized_data), figsize=(8, 6 * len(pre_normalized_data)))\n",
        "\n",
        "    for i, (param, values) in enumerate(pre_normalized_data.items()):\n",
        "        axs[i].plot(values)\n",
        "        axs[i].set_xlabel(\"Entry\")\n",
        "        axs[i].set_ylabel(param)\n",
        "        axs[i].set_title(f\"Pre-Normalization: {param}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Collect values for normalization\n",
        "    temp_values = []\n",
        "    humidity_values = []\n",
        "    wind_speed_values = []\n",
        "    wind_direction_values = []\n",
        "    pressure_values = []\n",
        "    elevation_values = []\n",
        "\n",
        "    for entry in data:\n",
        "        temp_values.append(entry[\"main\"][\"temp\"])\n",
        "        humidity_values.append(entry[\"main\"][\"humidity\"])\n",
        "        wind_speed_values.append(entry[\"wind\"][\"speed\"])\n",
        "        wind_direction_values.append(entry[\"wind\"][\"deg\"])\n",
        "        pressure_values.append(entry[\"main\"][\"pressure\"])\n",
        "        elevation_values.append(entry[\"elevation\"])\n",
        "\n",
        "    # Calculate mean and standard deviation\n",
        "    temp_mean = np.mean(temp_values)\n",
        "    temp_std = np.std(temp_values)\n",
        "    humidity_mean = np.mean(humidity_values)\n",
        "    humidity_std = np.std(humidity_values)\n",
        "    wind_speed_mean = np.mean(wind_speed_values)\n",
        "    wind_speed_std = np.std(wind_speed_values)\n",
        "    wind_direction_mean = np.mean(wind_direction_values)\n",
        "    wind_direction_std = np.std(wind_direction_values)\n",
        "    pressure_mean = np.mean(pressure_values)\n",
        "    pressure_std = np.std(pressure_values)\n",
        "    elevation_mean = np.mean(elevation_values)\n",
        "    elevation_std = np.std(elevation_values)\n",
        "\n",
        "    # Read existing project settings from JSON file\n",
        "    with open(project_settings_file_path, 'r') as settings_file:\n",
        "        project_settings = json.load(settings_file)\n",
        "\n",
        "    # Update or add new parameters to the project settings\n",
        "    project_settings[\"temp_mean\"] = temp_mean\n",
        "    project_settings[\"temp_std\"] = temp_std\n",
        "    project_settings[\"humidity_mean\"] = humidity_mean\n",
        "    project_settings[\"humidity_std\"] = humidity_std\n",
        "    project_settings[\"wind_speed_mean\"] = wind_speed_mean\n",
        "    project_settings[\"wind_speed_std\"] = wind_speed_std\n",
        "    project_settings[\"wind_direction_mean\"] = wind_direction_mean\n",
        "    project_settings[\"wind_direction_std\"] = wind_direction_std\n",
        "    project_settings[\"pressure_mean\"] = pressure_mean\n",
        "    project_settings[\"pressure_std\"] = pressure_std\n",
        "    project_settings[\"elevation_mean\"] = elevation_mean\n",
        "    project_settings[\"elevation_std\"] = elevation_std\n",
        "\n",
        "    # Write updated project settings to JSON file\n",
        "    with open(project_settings_file_path, 'w') as settings_file:\n",
        "        json.dump(project_settings, settings_file, indent=4)\n",
        "\n",
        "    normalized_data = []\n",
        "    for entry in data:\n",
        "        filename = entry[\"filename\"]\n",
        "        lat = entry[\"coord\"][\"lat\"]\n",
        "        lon = entry[\"coord\"][\"lon\"]\n",
        "        temp = entry[\"main\"][\"temp\"]\n",
        "        humidity = entry[\"main\"][\"humidity\"]\n",
        "        wind_speed = entry[\"wind\"][\"speed\"]\n",
        "        wind_direction = entry[\"wind\"][\"deg\"]\n",
        "        pressure = entry[\"main\"][\"pressure\"]\n",
        "        elevation = entry[\"elevation\"]\n",
        "        minutes_of_day = entry[\"minutesOfDay\"]\n",
        "        day_of_year = entry[\"dayOfYear\"]\n",
        "\n",
        "        # Normalization\n",
        "        normalized_lat = normalise_lat(lat)\n",
        "        normalized_lon = normalise_lon(lon)\n",
        "        normalized_temp = normalise_temp(temp, temp_mean, temp_std)\n",
        "        normalized_humidity = normalise_humidity(humidity, humidity_mean, humidity_std)\n",
        "        normalized_wind_speed = normalise_wind_speed(wind_speed, wind_speed_mean, wind_speed_std)\n",
        "        normalized_wind_direction = normalise_wind_direction(wind_direction, wind_direction_mean, wind_direction_std)\n",
        "        normalized_pressure = normalise_pressure(pressure, pressure_mean, pressure_std)\n",
        "        normalized_elevation = normalise_elevation(elevation, elevation_mean, elevation_std)\n",
        "        normalized_minutes_of_day = normalise_minutes_of_day(minutes_of_day)\n",
        "        normalized_day_of_year = normalise_day_of_year(day_of_year)\n",
        "\n",
        "        entry_dict = {\n",
        "            \"filename\": filename,\n",
        "            \"normalized_latitude\": normalized_lat,\n",
        "            \"normalized_longitude\": normalized_lon,\n",
        "            \"normalized_temperature\": normalized_temp,\n",
        "            \"normalized_humidity\": normalized_humidity,\n",
        "            \"normalized_wind_speed\": normalized_wind_speed,\n",
        "            \"normalized_wind_direction\": normalized_wind_direction,\n",
        "            \"normalized_pressure\": normalized_pressure,\n",
        "            \"normalized_elevation\": normalized_elevation,\n",
        "            \"normalized_minutes_of_day\": normalized_minutes_of_day,\n",
        "            \"normalized_day_of_year\": normalized_day_of_year\n",
        "        }\n",
        "        normalized_data.append(entry_dict)\n",
        "\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        json.dump(normalized_data, file, indent=4)\n",
        "\n",
        "    # Display graphs\n",
        "    labels = [\n",
        "        \"Normalized Temperature\",\n",
        "        \"Normalized Humidity\",\n",
        "        \"Normalized Wind Speed\",\n",
        "        \"Normalized Wind Direction\",\n",
        "        \"Normalized Pressure\",\n",
        "        \"Normalized Elevation\",\n",
        "        \"Normalized Minutes of Day\",\n",
        "        \"Normalized Day of Year\",\n",
        "        \"Normalized Latitude\",\n",
        "        \"Normalized Longitude\"\n",
        "    ]\n",
        "\n",
        "    values = [\n",
        "        [entry[\"normalized_temperature\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_humidity\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_wind_speed\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_wind_direction\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_pressure\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_elevation\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_minutes_of_day\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_day_of_year\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_latitude\"] for entry in normalized_data],\n",
        "        [entry[\"normalized_longitude\"] for entry in normalized_data]\n",
        "    ]\n",
        "\n",
        "    fig, axs = plt.subplots(len(labels), figsize=(8, 6 * len(labels)))\n",
        "\n",
        "    for i, ax in enumerate(axs):\n",
        "        ax.plot(values[i])\n",
        "        ax.set_xlabel(\"Entry\")\n",
        "        ax.set_ylabel(labels[i])\n",
        "        ax.set_title(labels[i])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "67CicNbGZfdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_json(json_database_path, json_database_normalised_path, project_settings_json_path)"
      ],
      "metadata": {
        "id": "R8MIyDAGLYLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio_duration_ms(file_path):\n",
        "  #this function just checks the duration of an audio file using tinytag\n",
        "    try:\n",
        "        audio = TinyTag.get(file_path)\n",
        "        duration_ms = int(audio.duration * 1000)\n",
        "        return duration_ms\n",
        "    except UnicodeDecodeError:\n",
        "        logger.error(f\"Unicode Decode Error for file: {file_path}\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def sort_and_bucket_audio_files(folder, min_length_ms, max_length_ms, max_variance_ms, bucketData_path):\n",
        "    audio_files = [os.path.join(folder, file) for file in os.listdir(folder) if file.endswith('.wav')]\n",
        "\n",
        "    logger.info(f\"sort_and_bucket_audio_files: Found {len(audio_files)} audio files.\")\n",
        "\n",
        "    # Get the duration of all the audio files\n",
        "    durations_ms = [get_audio_duration_ms(file) for file in audio_files]\n",
        "    audio_files = [file for file, duration in zip(audio_files, durations_ms) if min_length_ms <= duration <= max_length_ms]\n",
        "    durations_ms = [duration for duration in durations_ms if min_length_ms <= duration <= max_length_ms]\n",
        "\n",
        "\n",
        "    logger.info(f\"sort_and_bucket_audio_files: {len(audio_files)} audio files have a duration between {min_length_ms} ms and {max_length_ms} ms.\")\n",
        "\n",
        "    # Sort the durations and the audio file paths so they match\n",
        "    sorted_indices = np.argsort(durations_ms)\n",
        "    sorted_files = [audio_files[i] for i in sorted_indices]\n",
        "    sorted_durations = [durations_ms[i] for i in sorted_indices]\n",
        "\n",
        "    # Create an object to store the sorting and bucketing data\n",
        "    bucketed_files = []\n",
        "    current_bucket = [{'file': sorted_files[0], 'duration': sorted_durations[0]}]\n",
        "    current_max_duration = sorted_durations[0]\n",
        "\n",
        "    # Iterate through the sorted files and check if they fit within the max variance\n",
        "    for file, duration in zip(sorted_files[1:], sorted_durations[1:]):\n",
        "        if duration - current_max_duration > max_variance_ms:\n",
        "            # Update the durations of the files in the current bucket\n",
        "            current_bucket = [{'file': file_data['file'], 'duration': get_audio_duration_ms(file_data['file'])} for file_data in current_bucket]\n",
        "\n",
        "            # Calculate the longest duration in the current bucket\n",
        "            current_max_duration = max(file_data['duration'] for file_data in current_bucket)\n",
        "\n",
        "            bucketed_files.append({'files': current_bucket, 'max_duration': current_max_duration})\n",
        "\n",
        "            logger.info(f\"sort_and_bucket_audio_files: Bucket {len(bucketed_files)} created with {len(current_bucket)} audio files and max duration of {current_max_duration} ms.\")\n",
        "\n",
        "            current_bucket = [{'file': file, 'duration': duration}]\n",
        "            current_max_duration = duration\n",
        "        else:\n",
        "            current_bucket.append({'file': file, 'duration': duration})\n",
        "\n",
        "    # Update the durations of the files in the last bucket\n",
        "    current_bucket = [{'file': file_data['file'], 'duration': get_audio_duration_ms(file_data['file'])} for file_data in current_bucket]\n",
        "\n",
        "    # Calculate the longest duration in the last bucket\n",
        "    current_max_duration = max(file_data['duration'] for file_data in current_bucket)\n",
        "\n",
        "    bucketed_files.append({'files': current_bucket, 'max_duration': current_max_duration})\n",
        "\n",
        "\n",
        "    logger.info(f\"sort_and_bucket_audio_files: Bucket {len(bucketed_files)} created with {len(current_bucket)} audio files and max duration of {current_max_duration} ms.\")\n",
        "    logger.info(f\"sort_and_bucket_audio_files: Created {len(bucketed_files)} buckets in total.\")\n",
        "\n",
        "    # Saving bucket data as a JSON file\n",
        "    with open(os.path.join(bucketData_path, 'bucket_data.json'), 'w') as f:\n",
        "        json.dump(bucketed_files, f, indent=4)\n",
        "\n",
        "    logger.info(f\"sort_and_bucket_audio_files: Bucket data saved to {os.path.join(bucketData_path, 'bucket_data.json')}.\")\n",
        "\n",
        "\n",
        "\n",
        "def prepare_sequences(audio_folder, json_file, bucketData_path, element_duration_ms):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load bucket data\n",
        "    logger.info(\"prepare_sequences: Loading bucketing settings\")\n",
        "    with open(os.path.join(bucketData_path, 'bucket_data.json'), 'r') as f:\n",
        "        buckets = json.load(f)\n",
        "\n",
        "    # Instantiate the MelSpectrogram transformation\n",
        "    logger.info(\"prepare_sequences: Setting up MelSpectrogram transformation\")\n",
        "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=systemParams['master_sample_rate'],\n",
        "        n_fft=systemParams['mel_n_fft'],\n",
        "        hop_length=systemParams['mel_hop_length'],\n",
        "        n_mels=systemParams['mel_n_mels'],\n",
        "        normalized=systemParams['mel_normalized']\n",
        "    )\n",
        "\n",
        "    # Print the settings of the MelSpectrogram transformation\n",
        "    logger.info(\"prepare_sequences: MelSpectrogram settings:\")\n",
        "    logger.info(f\"prepare_sequences: Sample rate: {mel_spectrogram.sample_rate}\")\n",
        "    logger.info(f\"prepare_sequences: N FFT: {mel_spectrogram.n_fft}\")\n",
        "    logger.info(f\"prepare_sequences: Hop length: {mel_spectrogram.hop_length}\")\n",
        "    logger.info(f\"prepare_sequences: Number of Mel bins: {mel_spectrogram.n_mels}\")\n",
        "    logger.info(f\"prepare_sequences: Normalized: {mel_spectrogram.normalized}\")\n",
        "\n",
        "    logger.info(\"prepare_sequences: Loading normalized data\")\n",
        "    with open(json_file, 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    for bucket in buckets:\n",
        "        batch_size = int(bucket[\"max_duration\"] / element_duration_ms) + 1\n",
        "        logger.debug(f\"prepare_sequences: batch_size: {batch_size}\")\n",
        "\n",
        "        for file_data in bucket[\"files\"]:\n",
        "            audio_file = file_data[\"file\"]\n",
        "            audio_data, sr = librosa.load(audio_file, sr=systemParams['master_sample_rate'])\n",
        "            logger.debug(\"prepare_sequences: Loading audio file: \" + audio_file)\n",
        "\n",
        "            if len(audio_data) < batch_size * element_duration_ms * sr / 1000:\n",
        "                audio_data = np.pad(audio_data, (0, batch_size * int(element_duration_ms * sr / 1000) - len(audio_data)), mode='constant')\n",
        "\n",
        "            audio_elements = np.array_split(audio_data, batch_size)\n",
        "            logger.debug(\"prepare_sequences: Audio split into: \" + str(len(audio_elements)) + \" elements\")\n",
        "            logger.debug(\"prepare_sequences: Transforming audio to Spectrogram\")\n",
        "\n",
        "            audio_elements = [mel_spectrogram(torch.tensor(element).to(device)) for element in audio_elements]\n",
        "\n",
        "            batch_data = torch.stack(audio_elements)  # [batch_size, sequence_length, feature_size]\n",
        "            logger.debug(\"prepare_sequences: Audio elements Shape: \" + str(len(audio_elements)))\n",
        "\n",
        "            json_entry = next((entry for entry in json_data if entry[\"filename\"] == os.path.splitext(os.path.basename(audio_file))[0].replace('_P', '')), None)\n",
        "            if json_entry is None:\n",
        "                logger.error(\"prepare_sequences: No matching JSON entry found for audio file:\", audio_file)\n",
        "                continue\n",
        "\n",
        "            params = [\n",
        "                json_entry[\"normalized_latitude\"],\n",
        "                json_entry[\"normalized_longitude\"],\n",
        "                json_entry[\"normalized_wind_direction\"],\n",
        "                json_entry[\"normalized_humidity\"],\n",
        "                json_entry[\"normalized_wind_speed\"],\n",
        "                json_entry[\"normalized_wind_direction\"],\n",
        "                json_entry[\"normalized_pressure\"],\n",
        "                json_entry[\"normalized_elevation\"],\n",
        "                json_entry[\"normalized_minutes_of_day\"],\n",
        "                json_entry[\"normalized_day_of_year\"],\n",
        "            ]\n",
        "\n",
        "            conditioning_tensor = torch.tensor(params, device=device).unsqueeze(0).repeat(batch_size, 1)  # Repeat for each sequence_length\n",
        "            batch_params = conditioning_tensor  # [batch_size, num_params]\n",
        "\n",
        "            logger.info(\"prepare_sequences: batch_data shape\" + str(batch_data.shape))\n",
        "            logger.info(\"prepare_sequences: batch_params shape \" + str(batch_params.shape))\n",
        "            logger.info(\"prepare_sequences: Length of batch data \" + str(len(batch_data)))\n",
        "            logger.info(\"prepare_sequences: yielding batch\")\n",
        "            yield batch_data, batch_params, len(batch_data)\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, audio_dim, num_attention_heads, conditioning_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Define device here\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.hidden_state = None\n",
        "\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.attention_layers = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim) for _ in range(num_attention_heads)\n",
        "        ])\n",
        "\n",
        "        self.additional_linear_layer = nn.Linear(hidden_dim * num_attention_heads + hidden_dim, hidden_dim)\n",
        "        self.output_layer = nn.Linear(hidden_dim, audio_dim)\n",
        "        self.conditioning_layer = nn.Linear(conditioning_dim, hidden_dim)\n",
        "\n",
        "    def reset_hidden_state(self, batch_size):\n",
        "        h_0 = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(self.device)\n",
        "        c_0 = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(self.device)\n",
        "        self.hidden_state = (h_0, c_0)\n",
        "\n",
        "    def forward(self, x, conditioning):\n",
        "        batch_size, sequence_length, _ = x.shape\n",
        "\n",
        "        lstm_output, self.hidden_state = self.lstm(x, self.hidden_state)\n",
        "\n",
        "        logger.debug(f\"Generator forward: Shape of LSTM output: {lstm_output.shape}, expected: ({batch_size}, {sequence_length}, {self.lstm.hidden_size})\")\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(sequence_length):\n",
        "            attention_input = lstm_output[:, t, :]\n",
        "            conditioned_input = self.conditioning_layer(conditioning)\n",
        "\n",
        "            attention_input_conditioned = torch.cat((attention_input, conditioned_input), dim=-1)\n",
        "\n",
        "            logger.debug(f\"Generator forward: Shape of attention_input_conditioned: {attention_input_conditioned.shape}, expected: ({batch_size}, {self.lstm.hidden_size + self.conditioning_layer.out_features})\")\n",
        "\n",
        "            attention_outputs = []\n",
        "            for attention_layer in self.attention_layers:\n",
        "                attention_scores = attention_layer(attention_input_conditioned)\n",
        "                attention_weights = F.softmax(attention_scores, dim=0).unsqueeze(-1)\n",
        "                attention_weights = attention_weights.permute(0, 2, 1)\n",
        "                attended_output = attention_weights * lstm_output\n",
        "                attention_output = torch.sum(attended_output, dim=1)\n",
        "                attention_outputs.append(attention_output)\n",
        "\n",
        "            combined_output = torch.cat(attention_outputs, dim=1)\n",
        "            logger.debug(f\"Generator forward: Shape of combined_output: {combined_output.shape}, expected: ({batch_size}, {self.lstm.hidden_size * self.num_attention_heads})\")\n",
        "\n",
        "            additional_output = self.additional_linear_layer(torch.cat((combined_output, conditioned_input), dim=-1))\n",
        "            output = self.output_layer(additional_output)\n",
        "            logger.debug(f\"Generator forward: Shape of final output: {output.shape}, expected: ({batch_size}, {self.output_layer.out_features})\")\n",
        "\n",
        "            outputs.append(output.unsqueeze(1))\n",
        "\n",
        "        final_output = torch.cat(outputs, dim=1)\n",
        "        logger.debug(f\"Generator forward: Shape of final output: {final_output.shape}\")\n",
        "        return final_output\n",
        "\n",
        "\n",
        "\n",
        "# Training the generator\n",
        "def train_generator(discriminator, generator, batch_size, conditioning, optimizer, steps_per_element):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    logger.info(\"Training generator\")\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Reset the generator's hidden state\n",
        "    generator.reset_hidden_state(batch_size)\n",
        "\n",
        "    # Generate fake data\n",
        "    noise = torch.randn(batch_size, steps_per_element, systemParams['input_dim'], device=device)\n",
        "    logger.debug(f\"train_generator: Shape of noise: {noise.shape}, expected: ({batch_size}, steps_per_element, {systemParams['input_dim']})\")\n",
        "\n",
        "    # Apply conditioning to the noise\n",
        "    conditioned_noise = torch.cat((noise, conditioning), dim=-1)\n",
        "    logger.debug(f\"train_generator: Shape of conditioned_noise: {conditioned_noise.shape}, expected: ({batch_size}, steps_per_element, {systemParams['input_dim'] + conditioning_dim})\")\n",
        "\n",
        "    # Generate fake data\n",
        "    fake_data = generator(noise, conditioning)\n",
        "    logger.debug(f\"train_generator: Shape of fake_data: {fake_data.shape}, expected: ({batch_size}, steps_per_element, audio_dim)\")\n",
        "\n",
        "    # Reshape the fake_data and conditioning to match the discriminator's input shape\n",
        "    fake_data_reshaped = fake_data.view(batch_size, -1)\n",
        "    logger.debug(f\"train_generator: Shape of reshaped fake_data: {fake_data_reshaped.shape}, expected: ({batch_size}, {steps_per_element * audio_dim})\")\n",
        "\n",
        "    # Get the discriminator's prediction\n",
        "    prediction = discriminator(fake_data_reshaped)\n",
        "    logger.debug(f\"train_generator: Shape of discriminator's prediction: {prediction.shape}, expected: ({batch_size}, 1)\")\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    # Aim to fool the discriminator\n",
        "    g_loss = -torch.mean(prediction)\n",
        "    logger.info(\"train_generator: Generator loss: \", g_loss.item())\n",
        "    g_loss.backward()\n",
        "\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    return g_loss\n",
        "\n",
        "\n",
        "\n",
        "# Define the Discriminator class with LSTM\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, audio_dim, hidden_dim, num_layers, steps_per_element):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(audio_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "        self.steps_per_element = steps_per_element\n",
        "        self.hidden_cell = (torch.zeros(self.num_layers,1,self.hidden_dim),\n",
        "                            torch.zeros(self.num_layers,1,self.hidden_dim))\n",
        "\n",
        "    def reset_hidden_state(self, batch_size):\n",
        "        self.hidden_cell = (\n",
        "            torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device),\n",
        "            torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
        "        )\n",
        "    # ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        self.reset_hidden_state(batch_size)\n",
        "        logger.debug(f\"Discriminator Actual shape of x: {x.shape}\")\n",
        "        logger.debug(f\"Discriminator steps_per_element: {self.steps_per_element})\")\n",
        "\n",
        "        batch_size, seq_length_times_audio_dim = x.shape\n",
        "        audio_dim = seq_length_times_audio_dim // self.steps_per_element\n",
        "        x = x.view(batch_size, self.steps_per_element, audio_dim)  # Reshape the tensor to have 3 dimensions\n",
        "\n",
        "        logger.debug(f\"Discriminator input shape: {x.shape}, expected: ({batch_size}, {self.steps_per_element}, {audio_dim})\")\n",
        "\n",
        "        # LSTM\n",
        "        lstm_output, _ = self.lstm(x, self.hidden_cell)  # We don't care about the hidden states, so ignore them\n",
        "\n",
        "        # Use only the last sequence output\n",
        "        last_output = lstm_output[:, -1, :]\n",
        "        logger.debug(f\"Discriminator LSTM last output shape: {last_output.shape}, expected: ({batch_size}, {self.hidden_dim})\")\n",
        "\n",
        "        # Linear layer\n",
        "        output = self.output_layer(last_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_discriminator(discriminator, generator, real_data, conditioning, optimizer, steps_per_element):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    logger.info(\"train_discriminator: Training Discriminator\")\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 1. Train on Real Data\n",
        "    real_data = real_data.view(real_data.size(0), -1)  # Reshape real_data\n",
        "    # Generate predictions for real data\n",
        "    prediction_real = discriminator(real_data)\n",
        "    logger.debug(\"train_discriminator: Discriminator's prediction for real data: %s\", prediction_real.mean().item())\n",
        "\n",
        "\n",
        "    # 2. Train on Fake Data\n",
        "    # Generate fake data\n",
        "    noise = torch.randn(real_data.size(0), steps_per_element, systemParams['input_dim'], device=device)\n",
        "\n",
        "    # Generate fake data\n",
        "    fake_data = generator(noise, conditioning).detach()\n",
        "    fake_data = fake_data.view(fake_data.size(0), -1)  # Reshape fake_data\n",
        "    # Generate predictions for fake data\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    logger.debug(\"train_discriminator: Discriminator's prediction for fake data: %s\", prediction_fake.mean().item())\n",
        "\n",
        "    # Compute the Wasserstein Loss\n",
        "    d_loss = -torch.mean(prediction_real) + torch.mean(prediction_fake)\n",
        "\n",
        "    logger.info(\"train_discriminator: d_loss.requires_grad: %s\", d_loss.requires_grad)\n",
        "\n",
        "\n",
        "    # Calculate gradient penalty (lambda is the weighting factor, here assumed to be 10)\n",
        "    alpha = torch.rand(real_data.size(0), 1).to(device)\n",
        "\n",
        "    # Create interpolated data between real and fake\n",
        "    interpolates = (alpha * real_data + ((1 - alpha) * fake_data)).requires_grad_(True)\n",
        "    # Get discriminator's prediction for interpolated data\n",
        "    d_interpolates = discriminator(interpolates)\n",
        "    fake = torch.ones(real_data.size(0), 1).to(device)\n",
        "\n",
        "    # Calculate the gradients w.r.t interpolated data\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "\n",
        "    # Compute gradient penalty\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
        "    logger.info(\"train_discriminator: Gradient penalty: %s\", gradient_penalty.item())\n",
        "\n",
        "    # Add gradient penalty to the discriminator loss\n",
        "    d_loss += gradient_penalty\n",
        "    logger.info(\"train_discriminator: Discriminator loss: %s\", d_loss.item())\n",
        "\n",
        "    # Update weights\n",
        "    d_loss.backward()\n",
        "    logger.info(\"train_discriminator: d_loss.backward passed\")\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return d_loss\n",
        "\n",
        "\n",
        "def train_gan(gen, dis, audio_folder, json_file, bucketData_path, element_duration_ms, n_epochs, lr):\n",
        "    logger.info(\"train_gan: Training Gan\")\n",
        "    # Define device, loss function, and optimizers\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    gen = gen.to(device)\n",
        "    dis = dis.to(device)\n",
        "\n",
        "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
        "    optimizer_dis = torch.optim.Adam(dis.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Get the data from the generator function\n",
        "        for real, conditions, batch_size in prepare_sequences(audio_folder, json_file, bucketData_path, element_duration_ms):\n",
        "            real = real.permute(0, 2, 1).to(device)  # This will rearrange dimensions to (batch_size, sequence_length, num_features)\n",
        "            conditions = conditions.to(device)\n",
        "            max_sequence_length = real.shape[1]  # Infer max_sequence_length from the shape of the real data\n",
        "            logger.debug(f\"train_gan: max_sequence_length: {max_sequence_length})\")\n",
        "\n",
        "            logger.debug(f\"train_gan: Real data shape: {real.shape}, expected: ({batch_size}, {max_sequence_length}, {systemParams['input_dim']})\")\n",
        "\n",
        "            real = real.to(device)\n",
        "            conditions = conditions.to(device)\n",
        "\n",
        "            ###################\n",
        "            # Train Generator\n",
        "            ###################\n",
        "\n",
        "            gen.reset_hidden_state(batch_size)  # Reset hidden state\n",
        "            optimizer_gen.zero_grad()\n",
        "\n",
        "            # Generate fake samples\n",
        "            noise = torch.randn(batch_size, max_sequence_length, systemParams['input_dim']).to(device)\n",
        "            logger.debug(f\"train_gan: Noise shape: {noise.shape}, expected: ({batch_size}, {max_sequence_length}, {systemParams['input_dim']})\")\n",
        "\n",
        "            fake = gen(noise, conditions)\n",
        "            logger.debug(f\"train_gan: Fake data shape: {fake.shape}, expected: ({batch_size}, {max_sequence_length}, {systemParams['input_dim']})\")\n",
        "\n",
        "            # Calculate generator's loss based on discriminator's output\n",
        "            gen_loss = -dis(fake.view(fake.size(0), -1)).mean()\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            gen_loss.backward()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "            #######################\n",
        "            # Train Discriminator\n",
        "            #######################\n",
        "\n",
        "            dis.reset_hidden_state(batch_size)  # Reset hidden state\n",
        "            optimizer_dis.zero_grad()\n",
        "\n",
        "            # Train discriminator\n",
        "            dis_loss = train_discriminator(dis, gen, real.reshape(real.size(0), -1), conditions, optimizer_dis, systemParams['steps_per_element'])\n",
        "\n",
        "        # Printing losses after each epoch\n",
        "        logger.info(f'train_gan: Epoch [{epoch+1}/{n_epochs}] Loss D: {dis_loss.item()}, Loss G: {gen_loss.item()}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5x4OK5fEZCfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buckets = sort_and_bucket_audio_files(audio_folder, systemParams['bucket_min_duration_ms'], systemParams['bucket_max_duration_ms'], systemParams['bucket_max_size_variation_ms'], bucketData_path)\n"
      ],
      "metadata": {
        "id": "GocxAR3CeaxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "XJ_I83A2Z7VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(f\"Input dim: {systemParams['input_dim']}, type: {type(systemParams['input_dim'])}\")\n",
        "logger.info(f\"Hidden dim: {systemParams['hidden_dim']}, type: {type(systemParams['hidden_dim'])}\")\n",
        "logger.info(f\"Num layers: {systemParams['num_layers']}, type: {type(systemParams['num_layers'])}\")\n",
        "logger.info(f\"Mel n mels: {systemParams['mel_n_mels']}, type: {type(systemParams['mel_n_mels'])}\")\n",
        "logger.info(f\"Num attention heads: {systemParams['num_attention_heads']}, type: {type(systemParams['num_attention_heads'])}\")\n",
        "logger.info(f\"Conditioning dim: {systemParams['conditioning_dim']}, type: {type(systemParams['conditioning_dim'])}\")\n",
        "\n",
        "gen = Generator(systemParams['input_dim'], systemParams['hidden_dim'], systemParams['num_layers'], systemParams['mel_n_mels'], systemParams['num_attention_heads'], systemParams['conditioning_dim'])\n",
        "dis = Discriminator(systemParams['mel_n_mels'], systemParams['hidden_dim'], systemParams['num_layers'], systemParams['steps_per_element'])\n",
        "\n",
        "\n",
        "# Call the training function\n",
        "\n",
        "train_gan(gen, dis, audio_folder, json_database_normalised_path, bucketData_path, systemParams['sequence_element_length_ms'], systemParams['num_epochs'], systemParams['learning_rate'])"
      ],
      "metadata": {
        "id": "wrkSNmKlVEUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Connect to Weights and Biases for tracking progress\n",
        "wandb.init(project=\"audio-gan\")"
      ],
      "metadata": {
        "id": "shzA76G_ZNr4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}